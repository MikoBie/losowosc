---
title: "Motivational, personality, and situational determinants of the ability to produce random series"
description: |
    Method section.
author:
  - name: Mikołaj Biesaga and Szymon Talaga
    affiliation: The Robert Zajonc Institute for Social Studies
    affiliation_url: www.iss.uw.edu.pl/en/
date: "`r Sys.Date()`"
output: radix::radix_article
---

## 2. Method

```{r setup_env, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 8, fig.asp = 1)
```

```{r setup}
## Wczytaj pakiety
library(magrittr)
library(tidyverse)
library(reticulate)
library(lattice)
library(zoo)
library(MuMIn)
library(acss)
library(haven)
library(nlme)
library(kableExtra)
source("helpers/helpers.R")
## Ustaw temat ggplot()
theme_set(theme_classic())
## Środowisko Conda
use_condaenv("bdm")
```

### 2.1. Study 1

In the first study, participants were tested individually in sessions that lasted about 15 minutes. They were simply asked to produce a 300 elements binary series. We gathered the responses from the participants using a specially designed computer tool which is available on Git Hub (https://github.com/MikoBie/Survey).

```{r load_and_prepare_data}
## Wczytanie danych z wyniki_new.csv
data <- read_delim("dane/wyniki_new.csv", delim = ";") %>%
    rename_at(vars(matches("^\\d")), ~str_c("d", .x)) %>%
    mutate_at(vars(matches("^d\\d")), as.integer) %>%
    rename(id = X)

## Zamiana na format long
data_long <- gather(data, key = "Index", value = "Bit", matches("^d\\d")) %>%
    filter(!is.na(Bit)) %>%
    arrange(id) %>%
    group_by(id) %>% 
    summarize(seq = list(Bit)) %>%
    ungroup 
``` 

#### 2.1.1. Procedure and Design

The experiment followed a 2 x 3 factorial design, including two between-subjects variables: the mathematical experience and the task definition condition. We recruited as participants two groups of students who either studied Psychology or Chemistry at the University of Warsaw. We assumed that students who chose as their major Psychology had relateively small experience with concepts like randomness while students from the Chemistry Department were more familiar with them. We based our assumption on the number of obligatory courses students had to take in both departments. For Chemistry it was nearly 200 hours of subjects like Math, Physics, and Statistics during the first three years, while for Psychology it was just 90 hours of Statistics during five years. In both groups, participants were at random assigned to one of three experimental conditions: 1) the No Instruction Condition, 2) the Coin Tossing Condition, and 3) the Stock Market Condition. In all three conditions, we used a specially designed computer tool. It displayed every two seconds a red square. In the No Instruction Condition participants were simply asked to press in random order one of the two specially marked keys whenever they see a red square. In the Coin Tossing Condition, participants were instructed to imagine tossing a fair coin whenever they see a red square and press either key marked as tail or head. In the Stock Market Condition, participants were asked to imagine a stock market chart and to assume that price fluctuation is generated by a random process. They were instructed to try to predict whether the price in the next time step will go up or down and to press either key marked as an arrow up or down.

#### 2.1.2. Participants

The participants were students from the Psychology Department and the Chemistry Department at the University of Warsaw. A total of  $183$ subjects ($129\ females$), aged from 18 to 30 ($M = 21.54,\ SD = 2.12$), were randomly assigned to one of the experimental conditions. The procedure was approved by the ethics committee of the Robert Zajonc Institute for Social Studies at the University of Warsaw. All participants gave informed consent before taking part in the study.

#### 2.1.3. Data manipulation

Although the participants were instructed to only press relevant keys when they saw a red square some people pressed it more often and others less frequent than 300 times. Therefore, the length of the series varied between subjects from 218 to 1016 elements ($Median = 300$). However, there were only a few people who produced significantly longer series than others. Therefore, we cut off observations exceeding the typical length of the series, i.e. we cut off the last 10% of observations (with indexes longer than 313).

We used „pybdm" library in Python to compute algorithmic complexity of each series. It is an implementation of Block Decomposition Method which allows extending the power of Coding Theorem Method on longer strings. All other analyses were performed using R (R Core Team, 2019). We used packages „dplyr" (version 0.8.1), „magrittr" (version 1.5), „nlme” (version 3.1), and „ggplot2” (version 3.2.0) for data manipulation, processing, visualization, and mixed models computation.

For each participant, we computed the overall value of the series complexity and the rolling algorithmic complexity. The former was normalized because even though we cut off 10% of the longest indexes, the length of series still varied. Normalization of the algorithmic complexity allowed to compare a series of different lengths.  The rolling algorithmic complexity was based on the computation of algorithmic complexity for a sliding window of length from 5 to 9. That is because the length of the working memory capacity is $7\ \pm 2$ bits of information. Herein, we present the analysis only for the sliding window of length 8, but other analysis with reproducible R code might be found in Appendix A.

```{python prepare_strings}
import numpy as np
import pandas as pd
from bdm import BDMRecursive as BDM

def window_bdm(seq, bdm, k=7):
    return np.array([ bdm.bdm(seq[i:(i+k)]) for i in range(len(seq) - k) ])
    
data = r.data_long
data.id = data.id.astype(int)
data.seq = data.seq.apply(lambda x: np.array(x, dtype=int))

bdm = BDM(ndim=1, min_length=8)
seq8 = pd.DataFrame({'id': r.data_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 8))})
```


```{r data_processing}
seq8 <- tbl_df(py$seq8)

data <- select(data, -matches("^d\\d")) %>%
    filter(id %in% seq8$id) %>%
    left_join(select(seq8, id, cmx), by = "id")

seq8 <- seq8 %>%
    unnest() %>%
    group_by(id) %>%
    mutate(idx = 1:n(),
           cmx_r = rollmean(cmx_w, k = 8, align = "center", na.pad = TRUE)) %>%
    ungroup %>%
    left_join(select(data, -cmx), by = "id") %>%
    mutate(Condition = fct_relevel(as.factor(Condition), "zero")) %>%
    filter(idx < 313)  %>%
    mutate(cmx_wc = mean(cmx_w) - cmx_w)
```


#### 2.1.4. Results

```{r mean_difference_psychology_chemistry}
## Chemistry - Psychology
permutation_faculty <- permutaion_test(data = data, group_var = 'Faculty')
observed_difference <- data %>%
    group_by(Faculty) %>%
    summarise(mean = mean(cmx),
              sd = sd(cmx))
p_value(observed_difference = observed_difference, distribution = permutation_faculty)

## Coin - Zero
permutation_coin_zero <- data %>%
  filter(Condition != 'stock') %>%
  permutaion_test(data = ., group_var = 'Condition')
observed_difference <- data %>%
  filter(Condition != 'stock') %>%
  group_by(Condition) %>%
  summarise(mean = mean(cmx),
            sd = sd(cmx))
p_value(observed_difference = observed_difference, distribution = permutation_coin_zero)

## Coin - Stock
permutation_coin_stock <- data %>%
  filter(Condition != 'zero') %>%
  permutaion_test(data = ., group_var = 'Condition')
observed_difference <- data %>%
  filter(Condition != 'zero') %>%
  group_by(Condition) %>%
  summarise(mean = mean(cmx),
            sd = sd(cmx))
p_value(observed_difference = observed_difference, distribution = permutation_coin_stock)

## Stock - zero
permutation_stock_zero <- data %>%
  filter(Condition != 'coin') %>%
  permutaion_test(data = ., group_var = 'Condition')
observed_difference <- data %>%
  filter(Condition != 'coin') %>%
  group_by(Condition) %>%
  summarise(mean = mean(cmx),
            sd = sd(cmx))
p_value(observed_difference = observed_difference, distribution = permutation_stock_zero)
```

Before conducting a more detailed analysis, we tested the hypothesis whether the mathematical experience (H1) and the task definition condition (H2) affect the overall value of the series complexity. For testing these hypotheses we followed following one-sided permutation test of mean difference procedure. First, from the results, we resampled without replacement relevant groups 100,000 times. Second, for each resampling, we computed the difference between group means. Third, we calculated p-value as the proportion of the number of resampled difference greater than the observed difference to all resampled differences (the reproducible R script is in Appendix A). To test the hypothesis that students with more mathematical experience will produce series more complex than others we compared the difference between mean algorithmic complexity of series produced by chemistry students and psychology students. The difference between mean algorithmic complexity in group of psychology students ($N = 93,\ M = .757,\ SD = .223$) and chemistry students ($N = 90,\ M = .771,\ SD = .218$) was not significant, $p = .33$.

Although this result suggests that the mathematical experience does not affect the overall algorithmic complexity of produced series we would argue that this conclusion needs further examination. In this study, we interfered with mathematical experience based on the field of studies. Therefore, we did not control for individual differences. 

However, there were significant differences of mean algorithmic complexity between the task definition conditions. The mean algorithmic complexity in the Coin Tossing Condition ($N = 63,\ M = .797,\ SD = .193$) was greater than in the No Instruction Condition ($N = 59,\ M = .698,\ SD = .267$), $p = .01$. Similarly, the mean algorithmic complexity in the Stock Market Condition ($N = 61,\ M = .793,\ SD = .184$) was greater than in the No Instruction Condition ($N = 59,\ M = .698,\ SD = .267$), $p = .01$. Only the difference in means between the Coin Tossing Condition and the Stock Market Condition was not significant, $p = .46$.

The results indicate that the task definition conditions affect the overall algorithmic complexity of produced series. In the conditions (the Coin Tossing and the Stock Market conditions), in which task was defined in less abstract manner participants produced more complex series than in the No Instruction condition.

```{r plot1}
figure1 <- seq8 %>%
  mutate(Condition = case_when(Condition == "zero" ~ "No Instruction",
                               Condition == "stock" ~ "Stock Market",
                               Condition == "coin" ~ "Coin Tossing")) %>%
  group_by(Condition, idx) %>%
  summarise(cmx_w = mean(cmx_w)) %>%
  ggplot(aes(x = factor(Condition, levels = c("Coin Tossing", "Stock Market", "No Instruction")), y = (cmx_w), fill = Condition)) +
  geom_boxplot(show.legend = FALSE) +
  stat_boxplot(geom = "errorbar", width = .2) +
  labs(title = "",
       x = "Condition",
       y = "Algorithmic complexity")

figure1 %>%
  ggsave(filename = "figure_1.png",
       device = "png",
       dpi = 300,
       height = 4.5,
       width = 6)

```

Figure 1. The average algorithmic complexity by the definition condition.

```{r model8}
## Model Selection
model8 <- lme(log(cmx_w) ~ 1 +idx*Faculty + idx*Condition,
             random = ~1|id,
             correlation  = corARMA(form = ~idx|id, p = 1),
             data = seq8)
summary(model8)
r.squaredGLMM(model8)
d_cohen(model8)
```

In a more detailed analysis, we used the rolling algorithmic complexity. We performed the linear mixed-effects model to test following hypotheses: H3) the algorithmic complexity decreases over time, H3a) the task definition moderates the effect of time on algorithmic complexity of the series, and, H3b) the mathematical experience moderates the effect of time on algorithmic complexity of the series. We present herein analysis for a sliding window of the length 8 only. That is because this model fitted the data the best. The specification of the rest of the models is in Appendix A together with a replicable R script. The dependent variable (the algorithmic complexity) in the models was logged so back-transformed model predictions were bounded to be non-negative since there is no notion of negative randomness / algorithmic complexity. In all models as fixed effects we entered the time step, the task abstraction condition (with No Instruction Condition as a reference level in dummy coding), the mathematical experience condition (with Chemistry as a reference level in dummy coding) and interaction terms between the time step and the task abstraction condition, and between the time step and the mathematical experience condition. Goodness-of-fit of the models were assessed with marginal $R^2$ (variance retained by fixed effects only) and conditional $R^2$ (variance retained by the model as such).

In the model with the sliding window of length 8 as random effect, we had an intercept for subjects. The fitted model indicated several significant effects. There was a significant negative effect of the time step on the algorithmic complexity, $t(53111) = 2.63,\ d = .02,\ p = .009$. With each time step, the algorithmic complexity decreased by $.004\%\ \pm.001$ (see Figure 2. which presents this trend). This result supported the third hypothesis regarding the observed decline in the algorithmic complexity over time. However, hypothesis 3a and 3b were not supported. Neither the task definition nor the level of mathematical experience moderated the effect of time step on the algorithmic complexity (the detailed results are presented in Table 1.). However, similarly to the overall algorithmic complexity, there were significant differences between task definition conditions. The algorithmic complexity in the Coin Tossing Condition was $2.19\%\ \pm.73$ higher than in the No Instruction Condition, $t(179) = 2.96,\ d = .38,\ p = .004$. Similarly, in the Stock Market condition, the algorithmic complexity was higher $2.82\%\ \pm.74$ than in the No Instruction Condition, $t(179) = 2.63,\ d = .34,\ p = .009$.

```{r plot2}
figure2 <- seq8 %>%
  ungroup() %>%
  mutate(predict = predict(model8),
         ymin = predict - 1.96*predict(model8, se.fit = TRUE, level = 0)$se.fit,
         ymax = predict + 1.96*predict(model8, se.fit = TRUE, level = 0)$se.fit) %>%
  group_by(idx) %>%
  summarise(predict = mean(predict),
            ymin = mean(ymin),
            ymax = mean(ymax),
            cmx = mean(log(cmx_w))) %>%
  ggplot(aes(x = (idx), y = predict)) +
  geom_smooth(aes(ymin = ymin, ymax=ymax), stat = 'identity', inherit.aes = TRUE, color = 'black', size = .5) +
  geom_line(aes(x = (idx), y = cmx), alpha = .2, color = 'black') +
  labs(title = "",
       x = "Time step",
       y = "Logarithm of the Algorithmic Complexity")

figure2 %>%
  ggsave(filename = "figure_2.png",
       device = "png",
       dpi = 300,
       height = 4.5,
       width = 6)
```

Figure 2. The decline of the rolling algorithmic complexity over the time step. The grey line depicts the empirical change, while the black line shows value predicted by the model with the $95\%$ Confidence Interval.

The results suggest that although there is a significant difference between task definition conditions in average algorithmic complexity it does not affect the effect of the time step on the algorithmic complexity. The decline is constant across all conditions.

```{r table1}
Predictors_names <- rownames(coef(summary(model8)))
coef(summary(model8)) %>% 
  as.tibble() %>% 
  mutate(Predictors = Predictors_names) %>%
  select(Predictors,
         "Estimates" = 1,
         "Std. Error" = 2,
         "df*"=DF,
         "t-value",
         "p-value") %>%
  kable(caption = "Model specification") %>%
  footnote(general = 'Marginal R2 = 3.93%, Conditional R2=37.48% \nStd. Deviation of the random individual effects s=.048, p<.001 \n\\*Degrees of Freedom were adjusted with the Kenward-Roger Method \nThe model accounted for first-order auto-regressive errors correlation structure')
```

### Study 2.2.

In the second study, participants were recruited through the Polish Nationwide Opinion Poll Ariadna. It is a Polish Online Opinion Poll often used to conduct political surveys or scientific research. Depending on the declared length of the study users are gratified with points which they can exchange for prizes. During the research, participants were asked to produce 10 twelve elements binary series and to complete Polish versions of the Need for Cognition and the short version of the Need for Closure Scales.

```{r load_and_prepare_data2}
data2 <- read_sav("dane/Zbiór_Biesaga_los_ostateczny_v1.sav") %>%
  mutate(id = 1:n()) %>%
  select(-Id) %>%
  filter(survey_finish_time >= 656 & survey_finish_time < 1708) %>%
  rename_at(vars(matches("^v1_r\\d+")),
            ~str_extract(string = .x, pattern = '\\d+$') %>%
              str_c("pzp", .)) %>%
  rename_at(vars(matches("^v2_r\\d+")),
            ~str_extract(string = .x, pattern = '\\d+$') %>%
              str_c('pp', .)) %>%
  mutate_at(vars(matches("pp\\d+")), ~as.numeric(.)) %>%
  mutate_at(vars(matches("pzp\\d+")), ~as.numeric(.))
```

```{r tests_calculations}
data2 <- data2 %>%
  mutate_at(vars(matches("pp[2, 3, 8, 10, 13, 15, 17, 19, 22, 26, 28, 33, 34, 35]")), ~{6-.}) %>%
  mutate_at(vars(matches("pzp[2, 5, 10, 14, 15, 16, 17, 18, 20, 24, 30, 31]")), ~{7-.}) %>%
  mutate(year = as.numeric(year)) %>%
  select(-age) %>%
  rowwise() %>%
  mutate(preferowanie_porzadku = sum(pzp1, pzp6, pzp17, pzp19, pzp26, pzp27, pzp28),
         preferowanie_przewidywalnosci = sum(pzp5, pzp7, pzp9, pzp15, pzp16, pzp21, pzp22, pzp32),
         nietolerowanie_wieloznacznosci = sum(pzp3, pzp8, pzp12, pzp24, pzp25, pzp29),
         zamknietosc_umyslowa = sum(pzp2, pzp4, pzp20, pzp23, pzp30, pzp31),
         zdecydowanie = sum(pzp10, pzp11, pzp13, pzp14, pzp18),
         preferowanie_porzadku2 = sum(pzp6, pzp26, pzp27),
         preferowanie_przewidywalnosci2 = sum(pzp9, pzp21, pzp32),
         nietolerowanie_wieloznacznosci2 = sum(pzp3, pzp8, pzp29),
         zamknietosc_umyslowa2 = sum(pzp2, pzp20, pzp31),
         zdecydowanie2 = sum(pzp13, pzp14, pzp18),
         potrzeba_poznania = sum(pp1, pp2, pp3, pp4, pp5, pp6, pp7, pp8, pp9, pp10,
                                 pp11, pp12, pp13, pp14, pp15, pp16, pp17, pp18, pp19, pp20,
                                 pp21, pp22, pp23, pp24, pp25, pp26, pp27, pp28, pp29, pp30,
                                 pp31, pp32, pp33, pp34, pp35, pp36),
         warunek = as.character(warunek),
         warunek = if_else(warunek == "1", "homogeneous", "heterogeneous")) %>%
  select(-matches('pp\\d+|pzp\\d+'))

data2_time <- data2 %>%
  gather(key = "Index", value = "Bit", matches("war[[:digit:]]")) %>%
  filter(!is.na(Bit)) %>% 
  filter(Bit != 99) %>% 
  mutate(klucz = if_else(grepl(x = Index, pattern = "time"), 'time', 'seq'),
         ids = str_extract(Index, pattern = '^war1_\\d+|^war2g\\d+_|^war2rm\\d+_'),
         ids = if_else(grepl(x = ids, pattern = 'war1'),
                       str_extract(string = ids, pattern = '(\\d+)(?!.*\\d)'),
                       str_extract(string = ids, pattern = '([rmg]+\\d+)(?!.*\\d)')),
         ids = case_when(ids == 'rm1' ~ '1',
                         ids == 'g1' ~ '2',
                         ids == 'rm2' ~ '3',
                         ids == 'g2' ~ '4',
                         ids == 'rm3' ~ '5',
                         ids == 'g3' ~ '6',
                         ids == 'rm4' ~ '7',
                         ids == 'g4' ~ '8',
                         ids == 'rm5' ~ '9',
                         ids == 'g5' ~ '10',
                         TRUE ~ ids),
         ids = as.numeric(ids)) %>%
  select(id, ids, Bit, klucz) %>%
  group_by(id, ids, klucz) %>%
  mutate(idx = 1:n()) %>%
  spread(klucz, Bit) %>%
  filter(!is.na(seq))

data2_long <- data2_time %>%
  select(id, ids, seq) %>%
  group_by(id, ids) %>%
  summarise(seq = list(seq)) %>%
  filter(lengths(seq)>8)
```

#### 2.2.1. Procedure and Design

The study followed an experimental design, including one two-level between-subjects variable. First, participants were at random assigned to either the homogeneous instruction condition or the heterogeneous instruction condition. In both conditions, similarly to study 1, participants saw a red square every two seconds in ten 12-displays series. In the homogeneous condition for each series, they were asked to imagine tossing a fair coin and report the result whenever they saw a red square. In the heterogeneous condition, their task altered every second series. In the odd series, they were asked to imagine tossing a fair coin and report the result whenever they saw a red square. In the even series, participants were asked to imagine a stock market chart and to assume that price fluctuation is generated by a random process. They were instructed to try to predict whether the prices will go up or down in the next time step and to report the outcome every time they saw a red square. After completing the procedure of generating random series participants in both conditions were asked to fill in Polish versions of the Need for Cognition and the short version of the Need for Closure Scales.

#### 2.1.2. Participants

The participants were recruited through the Polish Nationwide Opinion Poll Ariadna. A total number of 266 subjects agreed to take part in the study. However, due to the unrealistic (short or long) time of completion and unfinished surveys we excluded 80 participants. Therefore, finally we had a sample of 186 participants ($134\ females$), aged from 18 to 77 ($M = 39.32,\ SD = 13.08$). They were at random assigned to one of the experimental conditions. The procedure was approved by the ethics committee of the Robert Zajonc Institute for Social Studies at the University of Warsaw. All participants gave informed consent before taking part in the study.

#### 2.1.3. Data manipulation

In online research, it is crucial to measure survey time and exclude participants who completed the task in unrealistic (short or long) time. In our case, we removed $15\%$ of the shortest answers and 15% of the longest. Although the participants were instructed to only press relevant keys when they saw a red square some people pressed it less frequent than 120 times. Therefore, the length of the series varies between subjects from 100 to 120 elements ($Median = 114$). 

Additionally, we removed $10\%$ of the shortest series (shorter than 9 elements). That was because we wanted to also be able to compute algorithmic complexity for the sliding window of lengths from 5 to 9.

We used „pybdm" library in Python to compute algorithmic complexity of each series. It is an implementation of Block Decomposition Method which allows extending the power of Coding Theorem Method on longer strings. All other analyses were performed using R (R Core Team, 2019). We used packages "dplyr" (version 0.8.1), "magrittr" (version 1.5), "nlme" (version 3.1), and "ggplot2" (version 3.2.0) for data manipulation, processing, visualization, and structural equation modeling.

For each participant, we computed the overall value of the series complexity. The former was normalized because even though we cut off series shorter than 9 elements, the length of series still varied. Normalization of the algorithmic complexity allowed to compare a series of different lengths.  The rolling algorithmic complexity was based on the computation of algorithmic complexity for a sliding window of length from 5 to 9. That is because the length of the working memory capacity is $7\ \pm2$ bits of information. We calculated algorithmic complexity for all the lengths separately and performed the analysis for all the lengths. However, even the best-fitted model did not yield any significant effects. Therefore, the analysis for models for a sliding window of length from 5 to 9 are only to be found in Appendix A.

```{python prepare_strings2}
import numpy as np
import pandas as pd
from bdm import BDMRecursive as BDM
    
data = r.data2_long
data.id = data.id.astype(int)
data.ids = data.ids.astype(int)
data.seq = data.seq.apply(lambda x: np.array(x, dtype=int))

bdm = BDM(ndim=1, min_length=7)
seq7 = pd.DataFrame({'id': r.data2_long.id.astype(int),
                     'ids': r.data2_long.ids.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm)})
```


```{r prepare_data_for_models}
seq7 <- py$seq7


data2 <- data2_long %>%
  select(id, ids) %>%
  left_join(data2) %>%
  left_join(seq7 %>% select(id, ids,cmx)) %>%
  select(-matches('war\\d.')) %>%
  left_join(data2_time %>% select(id, ids, idx, time) %>% group_by(id,ids) %>% summarise(time = sum(time)))
  
```

#### 2.2.4 Results

```{r model_all}
model_quadratic <- lme((cmx) ~ 1 +ids*warunek + I(ids^2)*warunek +
               preferowanie_porzadku2 +
               preferowanie_przewidywalnosci2 +
               nietolerowanie_wieloznacznosci2 +
               zamknietosc_umyslowa2 +
               potrzeba_poznania,
             random = ~ids|id,
             data = data2,
             correlation = corCAR1(form = ~ids|id),
             method = "ML")
summary(model_quadratic)
r.squaredGLMM(model_quadratic)
d_cohen(model_quadratic)
```

First, we computed algorithmic complexity for each series produced by participants. Afterward, we used the linear mixed-effects model to test following hypothesis: H4) the algorithmic complexity decreases over time, H4a) the instruction condition moderates the effect of time on the algorithmic complexity, H5) the need for cognition increases the algorithmic complexity, H6a) the preference for order and structure sub-scale of need for closure decreases the algorithmic complexity, H6b) the desire for predictability sub-scale of the need for cognition scale decrease the algorithmic complexity, H6c) the discomfort and ambiguity sub-scale of the need for closure scale increases the algorithmic complexity, H6d) the closed-mindedness sub-scale of the need for closure scale decreases the algorithmic complexity. The dependent variable (the algorithmic complexity) in the model was normalized because even though people were asked to produce a series of 12 elements, the length of the produced series varied. Normalization of the algorithmic complexity allowed to compare a series of different lengths. As fixed effects we entered the instruction condition (with the homogeneous condition as the reference level in dummy coding), the series number (we entered also a quadratic term for the series number because it increased the model fit), the interaction term between series number and the instruction condition, the order sub-scale from the need for closure, the ambiguity sub-scale from the need for closure scale, the closed-mindedness sub-scale from the need for closure scale, the predictability sub-scale from the need for closure scale, and the need for cognition scale. Goodness-of-fit of the model was assessed with marginal $R^2$ (variance retained by fixed effects only) and conditional $R^2$ (variance retained by the model as such). As random effects, we had an intercept for subjects and random effect of slope for the series number.

The fitted model indicated several significant effects. There was a significant negative effect of the series number on the algorithmic complexity, $t(1501)=4.396,\ d = .13,\ p<.001$. With each series, the algorithmic complexity decreased by $.045\ \pm.01$ points. However, since the quadratic term was also present, $t(1501)=3.826,\ d = .009,\ p<.001$, the linear decline of the algorithmic complexity was reduced by $.003\ \pm.0009$ point with each series. This result supported the fourth hypothesis regarding the observed decline in the algorithmic complexity over time (compare Figure 3.). However, hypothesis 4 did not account for the decrease of the algorithmic complexity decline with each series. It seems that the algorithmic complexity at some point even increased. This change in the trend requires further examination. Hypothesis 4a was not supported. The instruction manipulation affected neither the change of the algorithmic complexity over series nor the algorithmic complexity itself.

The observed trend herein was similar to the trend observed in Study 1. The algorithmic complexity decreased with each series. However, the expected effect of instruction was not present. The decline of the algorithmic complexity was the same in both conditions. Unlike, Study 1 the negative relationship between a series number and algorithmic complexity was quadratic. Therefore, the trend diminished with each series. This result might be attributed either to the difference between tasks in Study 1 and Study 2 or to the different experimental settings (online research vs classical research). Nevertheless, it requires further investigation.

```{r plot_3}
figure3 <- data2 %>%
  ungroup() %>%
  mutate(predict = predict(model_quadratic),
         ymin = predict - 1.96*predict(model_quadratic, se.fit = TRUE, level = 0)$se.fit,
         ymax = predict + 1.96*predict(model_quadratic, se.fit = TRUE, level = 0)$se.fit) %>%
  group_by(ids) %>%
  summarise(predict = mean(predict),
            cmx = mean(cmx),
            ymin = mean(ymin),
            ymax = mean(ymax)) %>%
  mutate(ids = (ids)) %>%
  ggplot(aes(x = (ids), y = predict)) +
  geom_smooth(aes(ymin = ymin, ymax=ymax), stat = 'identity', inherit.aes = TRUE, color = 'black', size = .5) +
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10)) +
  geom_jitter(data = data2 %>% ungroup, aes(x = (ids), y = cmx), alpha = .2, color = 'grey') +
  labs(title = "",
       x = "Series number",
       y = "Algorithmic Complexity") 

figure3 %>%
  ggsave(filename = "figure_3.png",
       device = "png",
       dpi = 300,
       height = 4.5,
       width = 6)
```

Figure 3. The scatter plot of algorithmic complexity against a series number. The points were jittered for the sake of clearer visualization. The black line depicts the fitted trend of decline of the normalized algorithmic complexity across the series.

Additionally, the fitted model allowed testing hypothesis regarding the Need for Cognition and sub-scales of the short version of the Need for Closure relationships with the algorithmic complexity. The Need for Cognition was possessively correlated with the average algorithmic complexity of the series, $t(175) = 2.54,\ d = .012,\ p < .05$. With the one-point increase on the Need for Cognition scale, there was $.003\ \pm.001$ increase in the algorithmic complexity. This result supported the hypothesis that people who are more inclined to challenging tasks produces more complex series. Hypothesis 6b regarding the relationship between preference for order and structure sub-scale from the Need for Closure Scale and the algorithmic complexity was not supported. However, the desire for predictability sub-scale was negatively correlated to the algorithmic complexity, $t(175) = 2.40,\ d = .083,\ p<.05$. With the one-point increase on the probability scale, the average algorithmic complexity of the series declined by $-.012\ \pm.008$. This result supported hypothesis people who prefer predictable environment produce less complex series. Hypothesis 6c regarding the relationship between discomfort with ambiguity sub-scale and the algorithmic complexity was not supported. However, the close-mindedness sub-scale was negatively correlated with the algorithmic complexity, $t(175)=2.39,\ d = .074,\ p<.05$. With the one-point increase in the close-mindedness sub-scale, the average algorithmic complexity declined by $-.017\ \pm.007$. People who do not like to have their opinion confronted with other produced series less complex. The detailed results are presented in Table 2. (the reproducible R code is in Appendix A).

The observed herein correlations allow to assume that the ability to produce random series might be attributed not only to situational determinants but also to personality. Especially the relationship between the algorithmic complexity and the need for cognition requires further investigation. It seems that the intellectual determinants of the ability to produce random series might be moderated by this relationship. Although the presented herein effects are interesting from the theoretical point of view some of them had negligible effects sizes. Therefore, further examination of the personality component of the ability to produce random series requires using statistical tests with higher statistical power.

```{r table2}
Predictors_names <- rownames(coef(summary(model_quadratic)))
coef(summary(model_quadratic)) %>% 
  as.tibble() %>% 
  mutate(Predictors = Predictors_names) %>%
  select(Predictors,
         "Estimates" = 1,
         "Std. Error" = 2,
         "df*"=DF,
         "t-value",
         "p-value") %>%
  kable(caption = "Table 2. Model specification") %>%
  footnote(general = 'Marginal R2 = 6.68%, Conditional R2=45.21% \nStd. Deviation of the random individual effects s=.015, p<.001 \n\\*Degrees of Freedom were adjusted with the Kenward-Roger Method \nThe model accounted for first-order auto-regressive errors correlation structure')
```

The analysis of the rolling algorithmic complexity with a sliding window of length from 5 to 9 did not show any significant effects. Therefore, we present their results only in Appendix A.

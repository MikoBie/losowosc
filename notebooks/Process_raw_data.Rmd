---
title: "The effect of context and individual differences in human-generated randomness"
description: |
    Process raw data.
output:
  bookdown::html_document2:
    toc: yes
    toc_depth: 3
    toc_float: yes
    number_sections: no
---

## README

Although this is an `R` markdown we use package `reticulate` to import some functions from `python`. Therefore, this script requires having an Anaconda environment created. The detailed instruction on how to set up the virtual environment and how to use it is described in the README.md file.

```{r setup_env, include=FALSE}
# Globals
ROOT <- here::here()
HERE <- file.path(ROOT, "notebooks")
DATA <- file.path(ROOT, "data", "proc")
```

```{r setup}
## Load necessary packages
library(magrittr)
library(tidyverse)
library(broom)
library(reticulate)
library(zoo)

## Activate Conda environment
use_condaenv("bdm")
```

## Study 1.

```{r load_and_prepare_data}
## Load Study 1. raw data
data <- read.csv2(file.path(ROOT,"data/Study_1.csv")) %>% 
    rename_at(vars(matches("^X\\d")), ~str_replace_all(pattern = "X", replacement = 'd', .x)) %>%
    mutate_at(vars(matches("^d\\d")), as.integer) %>%
    rename(id = X)

## Transform to long format
data_long <- gather(data, key = "Index", value = "Bit", matches("^d\\d")) %>%
    filter(!is.na(Bit)) %>%
    arrange(id) %>%
    group_by(id) %>% 
    mutate(idx = 1:n()) %>%
    #filter(idx < 313) %>%
    summarize(seq = list(Bit)) %>%
    filter(lengths(seq) < 314) %>%
    ungroup 
``` 


```{python compute_bdm}
## Import modules from conda environment
import numpy as np
import pandas as pd
from pybdm import BDM
from pybdm import PartitionIgnore, PartitionRecursive

## Create a function to compute algorithmic complexity in the window of length 8
def window_bdm(seq, bdm, k=8):
    return np.array([ bdm.nbdm(seq[i:(i+k)]) for i in range(len(seq) - k) ])

## Load r object to Python    
data = r.data_long
data.id = data.id.astype(int)
data.seq = data.seq.apply(lambda x: np.array(x, dtype=int))

## Compute algorithmic complexity
bdm_recursive = BDM(ndim=1, partition=PartitionRecursive, min_length=8)
bdm_ignore = BDM(ndim=1, partition=PartitionIgnore)
seq8 = pd.DataFrame({'id': r.data_long.id.astype(int),
                     'cmx': data.seq.apply(bdm_ignore.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm_recursive, k = 8))})
```

```{r data_processing}
## Read Python object to R
seq8 <- as_tibble(py$seq8)

## Join algorithmic complexity matrix with data
data <- select(data, -matches("^d\\d")) %>%
    filter(id %in% seq8$id) %>%
    left_join(select(seq8, id, cmx), by = "id") %>%
    mutate(Condition = case_when(Condition == "coin" ~ "Coin Tossing",
                                 Condition == "stock" ~ "Stock Market",
                                 Condition == "zero" ~ "No Instruction"))
   
           
## Prepare data for more detailed analysis
seq8 <- seq8 %>%
    unnest(cols = cmx_w) %>%
    mutate(cmx_w = as.vector(cmx_w)) %>%
    group_by(id) %>%
    mutate(idx = 1:n()) %>%
    ungroup %>%
    left_join(select(data, -cmx), by = "id") %>%
    filter(idx < 313)

## Write out processed data sets
write.csv2(seq8, file.path(DATA, "Study1_seq8.csv"))
write.csv2(data, file.path(DATA, "Study1.csv"))
```

## Study 2.

```{r load_and_prepare_data2}
## Load Study 2. raw data
data2 <- read.csv2(file.path(ROOT,'data/Study_2.csv')) %>%
  rename(id = X) %>%
  filter(survey_finish_time >= 656 & survey_finish_time < 1708) %>%
  rename_at(vars(matches("^v2_r\\d+")),
            ~str_extract(string = .x, pattern = '\\d+$') %>%
              str_c('nfc', .)) %>%
  mutate_at(vars(matches("pp\\d+")), ~as.numeric(.))
```

```{r scales_calculations}
## Compute Need for Cognition
data2 <- data2 %>%
  mutate_at(vars(matches("nfc[2, 3, 8, 10, 13, 15, 17, 19, 22, 26, 28, 33, 34, 35]")), ~{6-.}) %>%
  mutate(Year = as.numeric(Year)) %>%
  select(-Age) %>%
  rowwise() %>%
  mutate(need_for_cognition = sum(nfc1, nfc2, nfc3, nfc4, nfc5, nfc6, nfc7, nfc8, nfc9, nfc10,
                                 nfc11, nfc12, nfc13, nfc14, nfc15, nfc16, nfc17, nfc18, nfc19, nfc20,
                                 nfc21, nfc22, nfc23, nfc24, nfc25, nfc26, nfc27, nfc28, nfc29, nfc30,
                                 nfc31, nfc32, nfc33, nfc34, nfc35, nfc36),
         Condition = as.character(Condition),
         Condition = if_else(Condition == "1", "homogeneous", "heterogeneous")) %>%
  select(-matches('nfc\\d+'))

# Transform data to long format
data2_long <- data2 %>%
  gather(key = "Index", value = "Bit", matches("war[[:digit:]]")) %>%
  filter(!is.na(Bit)) %>% 
  filter(Bit != 99) %>% 
  mutate(klucz = 'seq',
         ids = str_extract(Index, pattern = '^war1_\\d+|^war2g\\d+_|^war2rm\\d+_'),
         ids = if_else(grepl(x = ids, pattern = 'war1'),
                       str_extract(string = ids, pattern = '(\\d+)(?!.*\\d)'),
                       str_extract(string = ids, pattern = '([rmg]+\\d+)(?!.*\\d)')),
         ids = case_when(ids == 'rm1' ~ '1',
                         ids == 'g1' ~ '2',
                         ids == 'rm2' ~ '3',
                         ids == 'g2' ~ '4',
                         ids == 'rm3' ~ '5',
                         ids == 'g3' ~ '6',
                         ids == 'rm4' ~ '7',
                         ids == 'g4' ~ '8',
                         ids == 'rm5' ~ '9',
                         ids == 'g5' ~ '10',
                         TRUE ~ ids),
         ids = as.numeric(ids)) %>%
  select(id, ids, Bit, klucz) %>%
  group_by(id, ids, klucz) %>%
  mutate(idx = 1:n()) %>%
  spread(klucz, Bit) %>%
  filter(!is.na(seq)) %>%
  select(id, ids, seq) %>%
  group_by(id, ids) %>%
  summarise(seq = list(seq)) %>%
  filter(lengths(seq)>2)
```

```{python compute_bdm2}
## Import modules from conda environment
import numpy as np
import pandas as pd
from pybdm import BDM
from pybdm import PartitionIgnore, PartitionRecursive

## Load r object to Python    
data = r.data2_long
data.id = data.id.astype(int)
data.ids = data.ids.astype(int)
data.seq = data.seq.apply(lambda x: np.array(x, dtype = int))

## Compute algorithmic complexity
bdm = BDM(ndim=1, partition=PartitionRecursive)
seq = pd.DataFrame({'id': r.data2_long.id.astype(int),
                     'ids': r.data2_long.ids.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm)})
```

```{r prepare_data_for_models}
## Load python object to R
seq <- py$seq

## Join algorithmic complexity matrix with data
data2 <- data2_long %>%
  select(id, ids) %>%
  left_join(data2) %>%
  left_join(seq %>% select(id, ids,cmx)) %>%
  select(-matches('war\\d.'))  

## Write out processed data set
write.csv2(data2, file.path(DATA,"Study2.csv"))
```

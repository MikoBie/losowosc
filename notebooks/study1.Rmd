---
title: "Randomness"
description: |
    Study 1
author:
  - name: Szymon Talaga 
  - name: Mikołaj Biesaga
date: "`r Sys.Date()`"
output: 
    distill::distill_article:
        self_contained: yes
    pdf_document:
        keep_tex: yes
---

```{r setup, include=FALSE}
# Globals
ROOT <- here::here()
HERE <- file.path(ROOT, "notebooks")
DATA <- file.path(ROOT, "data", "proc")

knitr::opts_chunk$set(
    echo = FALSE,
    message = FALSE,
    fig.width = 6,
    fig.height = 5,
    base.dir = file.path(ROOT, "figs", "study1/")
)
```

```{r init}
library(tidyverse)
library(broom)
library(patchwork)      # combining ggplot figures
library(quantreg)       # quantile regression routines
library(lme4)           # efficient linear mixed models with block matrix structures
library(lmerTest)       # testing utilities for lme4 models
library(emmeans)        # estimated marginal means and general contrasts
library(MuMIn)          # implements R2 for (G)LMMs
library(ggpubr)         # ggplot extensions

## GGPlot aesthetics
theme_set(theme_classic())

COLORS <- RColorBrewer::brewer.pal(8, "Set1")
options(
    ggplot2.discrete.color = COLORS,
    ggplot2.discrete.fill  = COLORS
)
```

```{r prepare_data}
data <- read_tsv(file.path(DATA, "study1.tsv")) %>%
    mutate(
        Sex       = fct_relevel(if_else(Sex == "m", "male", "female"), "male"),
        Hand      = fct_relevel(if_else(Hand == "r", "right", "left"), "right"),
        Condition = fct_relevel(Condition, "zero"),
        Math      = fct_relevel(if_else(Faculty == "chemistry", "math", "no math"), "no math"),
        Group     = interaction(Math, Condition, sep = " | "),
        cmx_w     = map(str_split(cmx_w, pattern = fixed(";")), as.numeric)
    ) %>%
    relocate(Math, Group, .before = "Faculty")
```

# Wprowadzenie

W tym raporcie analizuję dane ze `study1`. Główny nacisk jest na szczegółową analizę rozkładów w grupach przy użyciu
regresji kwantylowej. Jak zaraz zobaczymy pozwoli nam to lepiej zrozumieć efekt manipulacji eksperymentalnej.
W drugiej części raportu uzupełniam główny wynik o analizę zróżnicowania wewnątrz- i międzyosobowego przy użyciu
mieszanego modelu liniowego.

## Kontrola innych zmiennych

Pomijam kontrole zmiennych typu `Age`, `Sex` i `Hand` w raporcie. Sprawdzałem coś tam na szybko i chyba nie mają 
znaczania, ale warto by to sprawdzić trochę dokładniej.

# Znormalizowana złożoność w grupach

Poniższe wykresy przedstawiają rozkłady złożoności w grupach. Kluczowe tutaj są dwie rzeczy. Widzimy, że rozkłady
pomiędzy grupami z oraz bez treningu matematycznego są raczej podobne we wszystkich grupach eksperymentalnych
(co sugeruje brak efektu głównego zdolności matematyczych jak i ich interakcji z manipulacją eksperymentalną).

Druga kluczowa kwestia to to, że rozkłady w grupach eksperymentalnych są bardzo podobne, podczas gdy rozkład
w grupie kontrolnej (`zero`) ma wyraźnie więcej masy w dolnym ogonie.
To sugeruje, że manipulacja eksperymentalna może nie mieć istotnego wpływu na poziom generowanej złożoności jako takiej,
za to wpływa istotnie na samą możliwość aktywacji tej zdolności efektywnie zmniejszając odsetek osób generujących
ciągi o bardzo niskiej złożoności. Wykorzystamy teraz regresję kwantylową, żeby sprawdzić to bardziej formalnie.

```{r cmx_distributions_in_groups, fig.width = 8, fig.height = 8}
plt1 <- data %>%
    ggplot(aes(x = cmx, fill = Condition)) +
    geom_histogram(bins = 10, color = "white") +
    facet_wrap(~Group, ncol = 1L) +
    labs(x = "Normalized complexity", y = "Count") +
    guides(fill = FALSE)

plt2 <- data %>%
    ggplot(aes(sample = cmx, color = Condition)) +
    geom_qq_line(linetype = 2L, color = "black") +
    geom_qq() +
    facet_wrap(~Group, ncol = 1L) +
    labs(x = "Normal quantiles", y = "Observed quantiles")

plt1 | plt2
```
Najpierw jednak sprawdźmy, czy faktycznie efekty zdolności matematycznych są nieistotne. Rozkłady są dość nietypowe,
więc zamiast testów dla średnich wykorzystamy test sumy rang Wilcoxona i bardziej ogólną hipotezę dominacji 
stochastycznej. Poniższa tabela przedstawia wyniki testu Wilcoxona dla poszczególnych grup oraz dla efektu głównego
(`main`). Widzimy, że w żadnym przypadku nie zachodzi relacja stochastycznej dominacji między grupami.
Zatem zasadniczo rozkładu dzielonego ze względu na zdolności matrmatyczne są takie same, co widzimy też na wykresach.
W związku z tym w dalszej części nie będziemy już rozważać tego czynnika.

```{r cmx_nonparametric_interaction_tests}
c(
    list(main = data),
    split(data, data$Condition)
)%>%
    map2(names(.), ~{
        mutate(tidy(wilcox.test(cmx ~ Sex, data = .x, exact = FALSE)), condition = .y, .before = 1L)
    }) %>%
    bind_rows %>%
    select(
        Condition = condition,
        W = statistic,
        p = p.value
    )
```

Jako że nie interesują nas już zdolności matematyczne, to spójrzmy jeszcze raz na rozkłady w grupach eksperymentalnych.
Teraz widzimy jeszcze wyraźniej, że dolny ogon w grupie `zero` jest cięższy, co oznacza, że mamy w tym przypadku
wyraźnie więcej przypadków z bardzo niską złożonością generowanych ciągów. W grupach eksperymentalnych obserwacje
ze znormalizowaną złożonością poniżej $50\%$ prawie się nie pojawiają, zaś w grupie kontrolnej nie są wcale bardzo
rzadkie.

```{r cmx_condition_distributions, fig.height = 3, fig.width = 8}
data %>%
    ggplot(aes(x = cmx, fill = Condition)) +
    geom_histogram(bins = 10L, color = "white") +
    facet_wrap(~Condition, nrow = 1L) +
    labs(x = "Normalized complexity", y = "Count")
```

Poniżej przedstawione są współczynniki dla regresji kwantylowej w podziale na $3$ główne kwartyle wraz z 
$95\%$ przedziałami ufności (estymowanie minimów i maksimów jest w praktyce niemożliwe).
Grupa odniesienia to grupa kontrolna (`zero`). Widzimy, że efekty dla 1-szego kwartyla ($\tau = 0.25$) są wyraźnie
większe od zera (ich przedziały ufności). W przypadku mediany są one już znacznie słabsze i albo nieistotne albo
prawie nieistotne (`coin`). Dla 3-ciego kwartyla są one już nieistotne w obu przypadkach. Wyniki te potwierdzają
nasze wcześniejsze przypuszczenia. Zachodzą istotne różnice między grupami na poziomie niższych kwartyli, ale zanikają
one na poziomie wyższych kwartyli (mniej więcej od miediany w górę).

```{r cmx_quartile_regression}
# Full quantile process model
proc <- rq(cmx ~ Condition, tau = -1, data = data, method = "br")

# Quartile model
qreg <- rq(cmx ~ Condition, tau = 1:3/4, data = data, method = "br")
summary(qreg, se = "rank")
```

Poniżej przedstawiony jest wykres estymowanych pełnych procesów kwantylowych (w oparciu o $183$ obserwacje) w podziale
na grupy. Widzimy, że grupa `zero` wyraźnie odbiega (w dół) od grup eksperymentalnych dla kwantyli poniżej mediany.
Jednocześnie kwantyle powyżej mediany dla wszystkich trzech grup bardzo szybko zbiegają się.

Widzimy więc, że w istocie manipulacja eksperymentalna ma istotny wpływ na wyniki w dolnej połowie rozkładu, co oznacza,
że raczej wpływa ona na łatwiejszą aktywację umiejętności do losowania ciągów losowych niż jej zasadniczą efektywność.

```{r cmx_quantile_process}
t(proc$sol) %>%
    as_tibble %>%
    select(
        tau,
        zero  = `(Intercept)`,
        coin  = Conditioncoin,
        stock = Conditionstock
    ) %>%
    mutate(
        coin = zero + coin,
        stock = zero + stock
    ) %>%
    pivot_longer(-tau, names_to = "Condition", values_to = "Qbar") %>%
    mutate(Condition = fct_relevel(Condition, "zero")) %>%
    ggplot(aes(x = tau, y = Qbar, color = Condition, group = Condition)) +
    geom_line() +
    geom_vline(xintercept = .5, linetype = 2L) +
    labs(x = "Quantile", y = "Normalized complexity")
```

# Różnice indywidualne w generowaniu złożoności

W drugiej części raportu zbadamy, na ile można mówić o różnicach międzyosobowych w generowaniu ciągów losowych.
W tym celu skupimy się na złożoności liczonej w niewielkich oknach (np. $8$ elementowych), dzięki czemu uzyskamy
dla każdej osoby dość długi szereg czasowy. To pozwoli sprawdzić, jak duża część wariancji to fluktuacje wewnątrzosobowe
(rozbite na błąd/zmienność wewnątrzosobową i ewentualny trend w czasie --- zapewne spadkowy związany ze zmęczeniem)
oraz systematyczne różnice międzyosobowe wyrażone w postaci efektów losowych.

Naiwny model statystyczny dla tego problemu można oprzeć na standardowym liniowym modelu mieszanym.
Nie będzie to jednak rozwiązanie idealne, gdyż zmienna zależna (znormalizowana złożoność) zawiera się
w zakresie $[0, 1]$. Zauważmy przy tym, że standardowa transformacja logitowa nie zadziała, gdyż potencjalnie
wiele obserwacji może mieć złożoność równą dokładnie $0$ lub $1$. Potrzebny będzie więc bardziej złożony
model zakładający, że zmienna zależna generowana jest z rozkłady $\text{Beta}(\alpha, \beta)$.

```{r cmx_individual_differences_data}
df <- data %>%
    select(idx, Condition, cmx_w) %>%
    unnest(cmx_w) %>%
    group_by(idx) %>%
    mutate(
        t = 1:n(),
        .after = "idx"
    ) %>%
    ungroup
```

## Naiwny (gaussowski) model

W naiwnym modelu Gaussowskim (jednak jak zobaczymy na koniec nie jest on wcale zły w praktyce)
będziemy modelować znormalizowaną złożoność w oknie ($8$-elementowym) jako funkcję grupy eksperymentalnej
oraz czasu a także efektów specyficznych dla osób (efekty losowe). Kluczowe jest to, że przyzwolimy na
niezależną estymację wariancji efektów losowych w grupach. Dzięki temu będziemy mogli sprawdzić, jak manipulacje
eksperymentalne wpływają na zmienność między osobami.

Model będzie miał następującą postać:

$$
\texttt{cmx_w} = b_0 + (\texttt{zero})u_i + (\texttt{coin})(b_1 + v_i) + (\texttt{stock})(b_2 + w_i) + b_3t + e_i
$$
gdzie $(\texttt{zero})$, $(\texttt{coin})$ i $(\texttt{stock})$ to zmienne wskaźnikowe grup eksprymentalnych,
$u_i$, $v_i$ i $w_i$ to efekty losowe takie, że $u_i \sim \mathcal{N}(0, \sigma^2_u)$, 
$v_i \sim \mathcal{N}(0, \sigma^2_v)$ oraz $w_i \sim \mathcal{N}(0, \sigma^2_w)$, $t$ to krok czasowy (indeks okna),
zaś $e_i \sim \mathcal{N}(0, \sigma^2)$ to błąd losowy (zmienność wewnątrzosobowa).

Wartość uogólnionego $R^2$ wskazuje na raczej niewielką siłę efektu manipulacji eksperymentalnej i efektu zmęczenia
(brzegowe $R^2$ około $2.8\%$) i jednocześnie znaczny poziom zróżnicowania międzyosobowego
(warunkowe $R^2$ około $45.8\%$).

```{r cmx_individual_differences_gaussian}
lmm0 <- lmer(cmx_w ~ Condition + t + (1 | idx), data = df)

lmm1 <- lmer(
    formula = cmx_w ~ Condition + t +
        (0 + dummy(Condition, "zero") | idx) +
        (0 + dummy(Condition, "coin") | idx) +
        (0 + dummy(Condition, "stock") | idx),
    data = df
)

summary(lmm1)
r.squaredGLMM(lmm1)
```

Kontrasty efektów głównych (dla średniego indeksu okna) manipulacji eksperymentalnej pokazują, że grupy eksperymentalne
nie różnią się między sobą, ale róznią się istotnie od grupy kontrolnej, tj. miały przeciętnie wyższy poziom złożoności
algorytmicznej.

```{r cmx_individual_differences_fixed}
compare <- emmeans(lmm1, "Condition") %>%
    pairs(rev = TRUE, adjust = "holm")

compare
```

```{r cmx_individual_differences_random_profiling}
prof <- profile(lmm1, which = c("theta_"), signames = FALSE)
```

```{r cmx_individual_differences_random}
(ci <- confint(prof))

anova(lmm0, lmm1)
```

Poniżej przedstawione są przedziału ufności dla odchyleń standardowych efektów losowych (oraz błędu) na podstawie
profilowania wiarygodności modelu. Ponownie widać, że nie ma istotnych różnic między grupami eksperymentalnym.
Jednocześnie zmienność międzyosobowa w grupie kontrolnej (`zero`) jest istotnie większa. Wynik ten potwierdza
wcześniejszy rezultat z wykorzystaniem regresji kwantylowej.

Dodatkowo, pseudo-ANOVA (analiza dewiancji) porównująca model z wariancjami efektów losowych specyficznymi
dla grup z uproszczonym modelem, w którym jest jedna wariancja wspólna dla wszystkich obserwacji pokazuje,
że różnice między wariancjami grupowymi są istotne statystycznie.

Ostatecznie widzimy więc, że:

1. Manipulacja eksperymentalna (osadzenie procesu generowania losowości w nieabstrakcyjnym procesie) zmniejsza
   zróżnicowanie między respondentami.
2. Dzieje się to przede wszystkim poprzez istotne zmniejszenie odsetka osób generujących ciągi o bardzo niskiej
   złożoności algorytmicznej (poniżej połowy maksimum).
3. Oznacza to więc, że osadzenie procesu **pomaga aktywować** zdolność generowania losowości pomagając generować
   ciągi o conajmniej umiarkowanym poziomie złożoności. Jednocześnie nie ma istotnego wpływu na efektywność
   generowania ciągów wysoce złożonych.

```{r cmx_individual_differences_random_effects_plot}
eff <- tibble(
    effect = fct_inorder(c("zero", "coin", "stock", "residual")),
    sd = as.data.frame(VarCorr(lmm1))$sdcor,
    lo = ci[, 1],
    hi = ci[, 2]
)

eff %>%
    mutate(effect = fct_relevel(fct_reorder(effect, sd), "residual", after = 3L)) %>%
    ggplot(aes(x = effect, y = sd, color = effect)) +
    geom_segment(aes(xend = effect, y = lo, yend = hi), alpha = .5, size = 2) +
    geom_point(shape = 21L, fill = "white", size = 3) +
    labs(x = "", y = "Standard deviation", color = "")
```

Na koniec zauważmy tylko, że nasz model, pomimo że jego Gaussowskie założenia są trochę naiwne, jest wcale niezłą
reprezentacją danych. Rozkład reszt modelu jest dość normalny.

```{r cmx_individual_differences_model_distributions, fig.width = 8, fig.height = 3}
dat <- enframe(resid(lmm1))

plt1 <- dat %>%
    ggplot(aes(x = value)) +
    geom_histogram(bins = 10L, color = "white") +
    labs(x = "Residuals", y = "Count")

plt2 <- dat %>%
    ggplot(aes(sample = value)) +
    geom_qq_line(color = "dodgerblue") +
    geom_qq() +
    labs(x = "Normal quantiles", y = "Observed quantiles")

plt1 | plt2
```
Rozkłady efektów losowych są trochę brzydsze, ale pamiętajmy o tym, że w tym przypadku normalność nie jest tak ważna.
Większość typowych modeli mieszanych jest bardzo odporna na nieekstremalne przypadki złamania tego założenia
(https://arxiv.org/pdf/1201.1980.pdf).

```{r cmx_individual_differences_model_distributions_random_effecs, fig.width = 8}
dat <- ranef(lmm1)$idx %>%
    as_tibble %>%
    set_names("zero", "coin", "stock") %>%
    map_df(~if_else(.x == 0, NA_real_, .x)) %>%
    pivot_longer(everything(), names_to = "Condition") %>%
    drop_na

plt1 <- dat %>%
    ggplot(aes(x = value, fill = Condition)) +
    geom_histogram(bins = 10L, color = "white") +
    facet_wrap(~Condition, ncol = 1L) +
    labs(x = "Normalized complexity", y = "Count") +
    guides(fill = FALSE)

plt2 <- dat %>%
    ggplot(aes(sample = value, color = Condition)) +
    geom_qq_line(color = "dodgerblue") +
    geom_qq() +
    facet_wrap(~Condition, ncol = 1L) +
    labs(x = "Normal quantiles", y = "Observed quantiles")

plt1 | plt2
```

Tak że jedyny potencjalny problem z modelem to to, jak reprezentowany jest w nim trend związany ze zmęczniem
(efekt dla `t`). Jest on liniowy, więc teoretycznie może prowadzić do predykcji mniejszych niż $0$ lub większych niż
$1$. Jest to jednak dla nas efekt o chyba marginalnym znaczeniu, który kontrolujemy tak na wszelki wypadek,
więc nie wiem, czy to ma jakieś kluczowe znaczenie. Tak naprawdę jedyny realny powód, żeby próbować podejścia
Bayesowskiego z rozkładem Beta, to gdybyśmy faktycznie potrzebowali realistycznego modelu dla trendu
(lub innych nieogranicznych ilościowych zmiennych).

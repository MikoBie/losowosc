---
title: "Motivational and situational determinants ability to produce random series"
description: |
    Method section.
author:
  - name: Mikołaj Biesaga and Szymon Talaga
    affiliation: The Robert Zajonc Institute for Social Studies
    affiliation_url: www.iss.uw.edu.pl/en/
date: "`r Sys.Date()`"
output: radix::radix_article
---

## 2. Method

```{r setup_env, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 8, fig.asp = 1)
```

```{r setup}
## Wczytaj pakiety
library(magrittr)
library(tidyverse)
library(reticulate)
library(lattice)
library(zoo)
library(lme4)
library(lmerTest)
library(MuMIn)
library(acss)
library(haven)
library(nlme)
library(sjPlot)
library(kableExtra)
## Ustaw temat ggplot()
theme_set(theme_classic())
## Środowisko Conda
use_condaenv("bdm")
```

### 2.1. Study 1

In the first study, participants were tested individually in sessions that lasted about 15 minutes. They were simply asked to produce a 300 elements binary series. To gather the responses from the participants we used a specially designed computer tool which is available on GitHub (https://github.com/MikoBie/Survey).


```{r load_and_prepare_data}
## Wczytanie danych z wyniki_new.csv
data <- read_delim("dane/wyniki_new.csv", delim = ";") %>%
    rename_at(vars(matches("^\\d")), ~str_c("d", .x)) %>%
    mutate_at(vars(matches("^d\\d")), as.integer) %>%
    rename(id = X)

## Zamiana na format long
data_long <- gather(data, key = "Index", value = "Bit", matches("^d\\d")) %>%
    filter(!is.na(Bit)) %>%
    arrange(id) %>%
    group_by(id) %>% 
    summarize(seq = list(Bit)) %>%
    ungroup 
``` 

#### 2.1.1. Procedure and Design

The experiment followed a 2 x 3 factorial design, including two between-subjects variables: the mathematical experience and the task definition condition. We recruited as participants two groups of students who either studied Psychology or Chemistry at the University of Warsaw. We assumed that students who chose as their major Psychology have less experience with a concept like a randomness while students from the Chemistry Department are more familiar with it. We based our assumption on the number of obligatory courses students had to take in both departments. For Chemistry it was nearly 200 hours of subjects like Math, Physics, and Statistics during the first three years, while for Psychology it was just 90 hours of Statistics during 5 years. In both groups, participants were at random assigned to one of three experimental conditions: 1) the No Instruction Condition, 2) the Coin Tossing Condition, and 3) the Stock Market Condition. In all three conditions, we used a specially designed computer tool. It displayed every two seconds a red square. In the No Instruction Condition participants were simply asked to press in random order one of the two specially marked keys whenever they see a red square. In the Coin Tossing Condition, participants were instructed to imagine tossing a fair coin whenever they see a red square and press either key marked as tail or head. In the Stock Market Condition, participants were asked to imagine a stock market chart and to assume that price fluctuation is generated by a random process. They were instructed to try to predict whether the prices will go up or down and to press either key marked as an arrow up or down. 

#### 2.1.2. Participants

The participants were students from the Psychology Department and the Chemistry Department at the University of Warsaw. A total of $183$ subjects ($129$ females), aged from $18$ to $30$ ($M = 21.54,\ SD = 2.12$), were randomly assigned to one of the experimental conditions. The procedure was approved by the ethics committee of the Robert Zajonc Institute for Social Studies at the University of Warsaw. All participants gave informed consent before taking part in the study. 

#### 2.1.3. Data manipulation

Although the participants were instructed to only press relevant keys when they saw a red square some people pressed it more often and others less frequent than 300 times. Therefore, the length of the series varies between subjects from 218 to 1016 elements ($Median = 300$). However, we used only observations with indexes smaller than 313, thus we cut off the last 10% of observations. There were only a couple of people who produced a longer series.

We used „pybdm” library in Python to compute algorithmic complexity of each series. It is an implementation of Block Decomposition Method which allows extending the power of Coding Theorem Method on longer strings. All other analyses were performed using R (R Core Team, 2019). We used packages „dplyr” (version 0.8.1), „magrittr” (version 1.5),  lme4 (version 1.1), and ggplot2 (version 3.2.0) for data manipulation, processing, visualization, and mixed models computation. 

For each participant, we computed the overall value of the series complexity and the rolling algorithmic complexity. The latter was based on the computation of algorithmic complexity for a sliding window of length from 5 to 9. That is because the length of the working memory capacity is $7\pm2$ bits of information. We calculated algorithmic complexity for all the lengths separately and performed the analysis for all the lengths.

```{python prepare_strings}
import numpy as np
import pandas as pd
from bdm import BDMRecursive as BDM

def window_bdm(seq, bdm, k=7):
    return np.array([ bdm.bdm(seq[i:(i+k)]) for i in range(len(seq) - k) ])
    
data = r.data_long
data.id = data.id.astype(int)
data.seq = data.seq.apply(lambda x: np.array(x, dtype=int))

bdm = BDM(ndim=1, min_length=7)
seq7 = pd.DataFrame({'id': r.data_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm))})

bdm = BDM(ndim=1, min_length=5)
seq5 = pd.DataFrame({'id': r.data_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 5))})

bdm = BDM(ndim=1, min_length=9)
seq9 = pd.DataFrame({'id': r.data_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 9))})
                     
bdm = BDM(ndim=1, min_length=6)
seq6 = pd.DataFrame({'id': r.data_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 6))})

bdm = BDM(ndim=1, min_length=8)
seq8 = pd.DataFrame({'id': r.data_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 8))})
                     
bdm = BDM(ndim=1, min_length=15)
seq15 = pd.DataFrame({'id': r.data_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 15))})
                     


# seq5 = seq5.loc[seq5.cmx >= seq5.cmx.quantile(.05), :]
# seq7 = seq7.loc[seq7.cmx >= seq7.cmx.quantile(.05), :]
# seq9 = seq9.loc[seq9.cmx >= seq9.cmx.quantile(.05), :]
# seq6 = seq11.loc[seq6.cmx >= seq6.cmx.quantile(.05), :]
# seq8 = seq13.loc[seq8.cmx >= seq8.cmx.quantile(.05), :]
# seq15 = seq15.loc[seq15.cmx >= seq15.cmx.quantile(.05), :]
```


```{r data_processing}
seq7 <- tbl_df(py$seq7)
seq5 <- tbl_df(py$seq5)
seq9 <- tbl_df(py$seq9)
seq6 <- tbl_df(py$seq6)
seq8 <- tbl_df(py$seq8)
seq15 <- tbl_df(py$seq15)


data <- select(data, -matches("^d\\d")) %>%
    filter(id %in% seq7$id) %>%
    left_join(select(seq7, id, cmx), by = "id")

seq7 <- seq7 %>%
    unnest() %>%
    group_by(id) %>%
    mutate(idx = 1:n(),
           cmx_r = rollmean(cmx_w, k = 7, align = "center", na.pad = TRUE)) %>%
    ungroup %>%
    left_join(select(data, -cmx), by = "id") %>%
    mutate(Condition = fct_relevel(as.factor(Condition), "zero")) %>%
    filter(idx < 313) %>%
    group_by(id) %>%
    mutate(cmx_wc = mean(cmx_w) - cmx_w)

seq5 <- seq5 %>%
    unnest() %>%
    group_by(id) %>%
    mutate(idx = 1:n(),
           cmx_r = rollmean(cmx_w, k = 5, align = "center", na.pad = TRUE)) %>%
    ungroup %>%
    left_join(select(data, -cmx), by = "id") %>%
    mutate(Condition = fct_relevel(as.factor(Condition), "zero")) %>%
    filter(idx < 313)  %>%
    mutate(cmx_wc = mean(cmx_w) - cmx_w)

seq9 <- seq9 %>%
    unnest() %>%
    group_by(id) %>%
    mutate(idx = 1:n(),
           cmx_r = rollmean(cmx_w, k = 9, align = "center", na.pad = TRUE)) %>%
    ungroup %>%
    left_join(select(data, -cmx), by = "id") %>%
    mutate(Condition = fct_relevel(as.factor(Condition), "zero")) %>%
    filter(idx < 313)  %>%
    mutate(cmx_wc = mean(cmx_w) - cmx_w)

seq6 <- seq6 %>%
    unnest() %>%
    group_by(id) %>%
    mutate(idx = 1:n(),
           cmx_r = rollmean(cmx_w, k = 6, align = "center", na.pad = TRUE)) %>%
    ungroup %>%
    left_join(select(data, -cmx), by = "id") %>%
    mutate(Condition = fct_relevel(as.factor(Condition), "zero")) %>%
    filter(idx < 313)  %>%
    mutate(cmx_wc = mean(cmx_w) - cmx_w)


seq8 <- seq8 %>%
    unnest() %>%
    group_by(id) %>%
    mutate(idx = 1:n(),
           cmx_r = rollmean(cmx_w, k = 8, align = "center", na.pad = TRUE)) %>%
    ungroup %>%
    left_join(select(data, -cmx), by = "id") %>%
    mutate(Condition = fct_relevel(as.factor(Condition), "zero")) %>%
    filter(idx < 313)  %>%
    mutate(cmx_wc = mean(cmx_w) - cmx_w)


seq15 <- seq15 %>%
    unnest() %>%
    group_by(id) %>%
    mutate(idx = 1:n(),
           cmx_r = rollmean(cmx_w, k = 15, align = "center", na.pad = TRUE)) %>%
    ungroup %>%
    left_join(select(data, -cmx), by = "id") %>%
    mutate(Condition = fct_relevel(as.factor(Condition), "zero")) %>%
    filter(idx < 313)  %>%
    mutate(cmx_wc = mean(cmx_w) - cmx_w)

```

```{r model5}
# ## Model selection
# model5 <- lme(log(cmx_w) ~ 1 +idx*Faculty + idx*Condition,
#              random = ~idx|id,
#              data = seq5)
# model5.4 <- update(model5,correlation = corARMA(form = ~idx|id, p = 1))
# anova(model5, model5.4)
# model5.5 <- update(model5.4,random = ~1|id)
# anova(model5.5, model5.4)
# model5.6 <- update(model5.5, random = ~idx-1|id )
# anova(model5.6,model5.4)
# #model5 <- update(model2,correlation = corARMA(form = ~idx|id, p = 2))
# #model6 <- update(model5, correlation = corARMA(form = ~idx|id, p = 7))
# #anova(model3, model4, model5, model6, model7)
# 
# ## Errors diagnostics
# par(mfrow = c(1,2))
# plot(model5.4)
# #qqnorm(model2,~ranef(., level = 1))
# qqnorm(model5.4, abline = c(0,1))
# plot(model5.4, resid(., type = 'normalized') ~ fitted(.))
# plot(model5.4,resid(.,type="pearson") ~ idx,type=c("p","smooth"))
# boxplot(resid(model5.4, type = 'normalized') ~ seq5$Condition)
# boxplot(resid(model5.4, type = 'normalized') ~ seq5$Faculty)
# 
# ## Autocorrelation Diagnostics
# acf(resid(model5.4, type = 'normalized'))
# pacf(resid(model5.4, type = 'normalized'))
# acf(resid(model5.4))
# pacf(resid(model5.4))
# 
# ## Summary
# r.squaredGLMM(model5.4)
# summary(model5.4)
# seq5 <- seq5 %>%
#   mutate(predict = predict(model5.4))
```


```{r model6}
# ## Model specification
# model6 <- lme(log(cmx_w) ~ 1 +idx*Faculty + idx*Condition,
#              random = ~idx|id,
#              data = seq6)
# model6.4 <- update(model6,correlation = corARMA(form = ~idx|id, p = 1))
# anova(model6, model6.4)
# model6.5 <- update(model6.4,random = ~1|id)
# anova(model6.5, model6.4)
# model6.6 <- update(model6.5, random = ~idx-1|id )
# anova(model6.6,model6.4)
# #model5 <- update(model2,correlation = corARMA(form = ~idx|id, p = 2))
# #model6 <- update(model5, correlation = corARMA(form = ~idx|id, p = 7))
# #anova(model3, model4, model5, model6, model7)
# 
# ## Error Diagnostics
# par(mfrow = c(1,2))
# plot(model6.6)
# #qqnorm(model2,~ranef(., level = 1))
# qqnorm(model6.6, abline = c(0,1))
# plot(model6.6, resid(., type = 'normalized') ~ fitted(.), type = c('p', 'smooth'))
# boxplot(resid(model6.6, type = 'pearson') ~ seq6$Condition)
# boxplot(resid(model6.6, type = 'pearson') ~ seq6$Faculty)
# 
# ## Autocorrelation Diagnostics
# acf(resid(model6.6, type = 'normalized'))
# pacf(resid(model6.6, type = 'normalized'))
# acf(resid(model6.6))
# pacf(resid(model6.6))
# 
# ## Summary
# r.squaredGLMM(model6.6)
# summary(model6.6)
# seq6 <- seq6 %>%
#   mutate(predict = predict(model6.4))
```

```{r model7}
# ## Model Selection
# model7 <- lme(log(cmx_w) ~ 1 +idx*Faculty + idx*Condition,
#              random = ~idx|id,
#              data = seq7)
# model7.4 <- update(model7,correlation = corARMA(form = ~idx|id, p = 1))
# anova(model7, model7.4)
# model7.5 <- update(model7.4,random = ~1|id)
# anova(model7.5, model7.4)
# model7.6 <- update(model7.4, random = ~idx-1|id )
# anova(model7.6,model7.4)
# #model5 <- update(model2,correlation = corARMA(form = ~idx|id, p = 2))
# #model6 <- update(model5, correlation = corARMA(form = ~idx|id, p = 7))
# #anova(model3, model4, model5, model6, model7)
# 
# ## Error Diagnostics
# par(mfrow = c(1,2))
# plot(model7.5)
# #qqnorm(model2,~ranef(., level = 1))
# qqnorm(model7.5, abline = c(0,1))
# plot(model7.5, resid(., type = 'normalized') ~ fitted(.))
# plot(model7.5,resid(.,type="pearson") ~ idx,type=c("p","smooth"))
# boxplot(resid(model7.5, type = 'normalized') ~ seq7$Condition)
# boxplot(resid(model7.5, type = 'normalized') ~ seq7$Faculty)
# 
# ## Autocorrelation Diagnostics
# acf(resid(model7.5, type = 'normalized'))
# pacf(resid(model7.5, type = 'normalized'))
# acf(resid(model7.5))
# pacf(resid(model7.5))
# 
# ## Summary
# r.squaredGLMM(model7.5)
# summary(model7.5)
# seq7 <- seq7 %>%
#   ungroup() %>%
#   mutate(predict = predict(model7.5))
```

```{r model8}
## Model Selection
model8 <- lme(log(cmx_w) ~ 1 +idx*Faculty + idx*Condition,
             random = ~idx|id,
             data = seq8)
model8.4 <- update(model8,correlation = corARMA(form = ~idx|id, p = 1))
anova(model8, model8.4)
model8.5 <- update(model8.4,random = ~1|id)
# anova(model8.5, model8.4)
# model8.6 <- update(model8.5, random = ~idx-1|id )
# anova(model8.6,model8.4)
# #model5 <- update(model2,correlation = corARMA(form = ~idx|id, p = 2))
# #model6 <- update(model5, correlation = corARMA(form = ~idx|id, p = 7))
# #anova(model3, model4, model5, model6, model7)
# model8.7 <- update(model8.5, correlation = corARMA(form = ~1|id, p = 1))
# 
# ## Error Diagnostics
# par(mfrow = c(1,2))
# plot(model8.5)
# #qqnorm(model2,~ranef(., level = 1))
# qqnorm(model8.5, abline = c(0,1))
# plot(model8.5, resid(., type = 'normalized') ~ fitted(.))
# plot(model8.5,resid(.,type="pearson") ~ idx,type=c("p","smooth"))
# boxplot(resid(model8.5, type = 'normalized') ~ seq8$Condition)
# boxplot(resid(model8.5, type = 'normalized') ~ seq8$Faculty)
# 
# ## Autocorrealtion Diagnostics
# acf(resid(model8.5, type = 'normalized'))
# pacf(resid(model8.5, type = 'normalized'))
# acf(resid(model8.7))
# pacf(resid(model8.7))
# 
# ## Summary
# r.squaredGLMM(model8.5)
# summary(model8.5)
# seq8 <- seq8 %>%
#   mutate(predict = predict(model8.5))
```

```{r model9}
# ## Model Selection
# model9 <- lme(log(cmx_w) ~ 1 +idx*Faculty + idx*Condition,
#              random = ~idx|id,
#              data = seq9)
# model9.4 <- update(model9,correlation = corARMA(form = ~idx|id, p = 1))
# anova(model9, model9.4)
# model9.5 <- update(model9.4,random = ~1|id)
# anova(model9.5, model9.4)
# model9.6 <- update(model9.5, random = ~idx-1|id )
# anova(model9.6,model9.4)
# #model5 <- update(model2,correlation = corARMA(form = ~idx|id, p = 2))
# #model6 <- update(model5, correlation = corARMA(form = ~idx|id, p = 7))
# #anova(model3, model4, model5, model6, model7)
# 
# ## Error Diagonostics
# par(mfrow = c(1,2))
# plot(model9.5)
# #qqnorm(model2,~ranef(., level = 1))
# qqnorm(model9.5, abline = c(0,1))
# plot(model9.5, resid(., type = 'normalized') ~ fitted(.))
# plot(model9.5,resid(.,type="pearson") ~ idx,type=c("p","smooth"))
# boxplot(resid(model9.5, type = 'normalized') ~ seq9$Condition)
# boxplot(resid(model9.5, type = 'normalized') ~ seq9$Faculty)
# 
# ## Autocorrelation Diagnostics
# acf(resid(model9.5, type = 'normalized'))
# pacf(resid(model9.5, type = 'normalized'))
# acf(resid(model9.5))
# pacf(resid(model9.5))
# 
# ## Summary
# r.squaredGLMM(model9.5)
# summary(model9.5)
# seq9 <- seq9 %>%
#   mutate(predict = predict(model9.5))
```

```{r model_comparison}
## I am not sure if we can do that this way.
## AIC(model5.4,model6.6, model7.5, model8.5, model9.5)

```



#### 2.1.4. Results

```{r mean_difference_psychology_chemistry}
## Function to compute a naive permutation test. It takes data (obviously), number of iterations, and grouping variable. It returns series of differences of mean and differences of sd.
permutaion_test <- function(data = data,R = 100000,group_var = 'Faculty'){
  
  results_mean <- vector(mode = 'numeric', length = R)
  results_sd <- vector(mode = 'numeric', length = R)
  
  group_n <- data %>%
    group_by_at(group_var) %>%
    summarise(n = n()) %$%
    {n[1]}
  
  total_n <- data %>%
    nrow
  
  set.seed(8710)
  
  for(i in c(1:R)){
    index <- sample(total_n, group_n, replace = FALSE)
    results_mean[i] <- mean(data$cmx[index]) - mean(data$cmx[-index])
    results_sd[i] <-  sd(data$cmx[-index]) - sd(data$cmx[index])
  }
  results <- tibble(diff_means = results_mean,
                    diff_sd = results_sd)
  return(results)
}
## Function which computes p for permutation test. It takes a data table with column mean with observed difference in means and sd with observed difference in sd. As a second argument it takes result of permutation test. It returns a data frame with p values for difference in means and sd.
p_value <- function(observed_difference, distribution){
  nperm <- nrow(distribution)
  mean_diff <- observed_difference$mean[1] - observed_difference$mean[2]
  sd_diff <- observed_difference$sd[2] - observed_difference$sd[1]
  mean_p <- (sum(distribution$diff_means >= mean_diff) +1) / (nperm +1)
  sd_p <- (sum(distribution$diff_sd >= (mean_diff)) +1) / (nperm +1)
  results <- tibble(mean = mean_p, sd = sd_p)
  return(results)
}

## Chemistry - Psychology
permutation_faculty <- permutaion_test(data = data, group_var = 'Faculty')
observed_difference <- data %>%
    group_by(Faculty) %>%
    summarise(mean = mean(cmx),
              sd = sd(cmx))
p_value(observed_difference = observed_difference, distribution = permutation_faculty)

## Coin - Zero
permutation_coin_zero <- data %>%
  filter(Condition != 'stock') %>%
  permutaion_test(data = ., group_var = 'Condition')
observed_difference <- data %>%
  filter(Condition != 'stock') %>%
  group_by(Condition) %>%
  summarise(mean = mean(cmx),
            sd = sd(cmx))
p_value(observed_difference = observed_difference, distribution = permutation_coin_zero)

## Coin - Stock
permutation_coin_stock <- data %>%
  filter(Condition != 'zero') %>%
  permutaion_test(data = ., group_var = 'Condition')
observed_difference <- data %>%
  filter(Condition != 'zero') %>%
  group_by(Condition) %>%
  summarise(mean = mean(cmx),
            sd = sd(cmx))
p_value(observed_difference = observed_difference, distribution = permutation_coin_stock)

## Stock - zero
permutation_stock_zero <- data %>%
  filter(Condition != 'coin') %>%
  permutaion_test(data = ., group_var = 'Condition')
observed_difference <- data %>%
  filter(Condition != 'coin') %>%
  group_by(Condition) %>%
  summarise(mean = mean(cmx),
            sd = sd(cmx))
p_value(observed_difference = observed_difference, distribution = permutation_stock_zero)
```
```{r contrasts}
# ## Psychology: Coin - Zero *
# permutation_coin_zero <- data %>%
#   filter(Faculty == 'psychology') %>%
#   filter(Condition != 'stock') %>%
#   permutaion_test(data = ., group_var = 'Condition')
# observed_difference <- data %>%
#   filter(Faculty == 'psychology') %>%
#   filter(Condition != 'stock') %>%
#   group_by(Condition) %>%
#   summarise(mean = mean(cmx),
#             sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_coin_zero)
# 
# ## Psychology: Coin - Stock
# permutation_coin_stock <- data %>%
#   filter(Faculty == 'psychology') %>%
#   filter(Condition != 'zero') %>%
#   permutaion_test(data = ., group_var = 'Condition')
# observed_difference <- data %>%
#   filter(Condition != 'zero') %>%
#   group_by(Condition) %>%
#   summarise(mean = mean(cmx),
#             sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_coin_stock)
# 
# ## Psychology: Stock - zero
# permutation_stock_zero <- data %>%
#   filter(Faculty == 'psychology') %>%
#   filter(Condition != 'coin') %>%
#   permutaion_test(data = ., group_var = 'Condition')
# observed_difference <- data %>%
#   filter(Condition != 'coin') %>%
#   group_by(Condition) %>%
#   summarise(mean = mean(cmx),
#             sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_stock_zero)
# 
# ## Chemistry: Coin - Zero
# permutation_coin_zero <- data %>%
#   filter(Faculty == 'chemistry') %>%
#   filter(Condition != 'stock') %>%
#   permutaion_test(data = ., group_var = 'Condition')
# observed_difference <- data %>%
#   filter(Faculty == 'chemistry') %>%
#   filter(Condition != 'stock') %>%
#   group_by(Condition) %>%
#   summarise(mean = mean(cmx),
#             sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_coin_zero)
# 
# ## Chemistry: Coin - Stock
# permutation_coin_stock <- data %>%
#   filter(Faculty == 'chemistry') %>%
#   filter(Condition != 'zero') %>%
#   permutaion_test(data = ., group_var = 'Condition')
# observed_difference <- data %>%
#   filter(Faculty == 'chemistry') %>%
#   filter(Condition != 'zero') %>%
#   group_by(Condition) %>%
#   summarise(mean = mean(cmx),
#             sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_coin_stock)
# 
# ## Chemistry: Stock - zero *
# permutation_stock_zero <- data %>%
#   filter(Faculty == 'chemistry') %>%
#   filter(Condition != 'coin') %>%
#   permutaion_test(data = ., group_var = 'Condition')
# observed_difference <- data %>%
#   filter(Faculty == 'chemistry') %>%
#   filter(Condition != 'coin') %>%
#   group_by(Condition) %>%
#   summarise(mean = mean(cmx),
#             sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_stock_zero)
```

```{r contrast_faculty}
# ## Chemistry - Psychology: coin
# permutation_faculty <- data %>%
#   filter(Condition == 'coin') %>%
#   permutaion_test(data = ., group_var = 'Faculty')
# observed_difference <- data %>%
#   filter(Condition == 'coin') %>%
#   group_by(Faculty) %>%
#   summarise(mean = mean(cmx),
#               sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_faculty)
# 
# ## Chemistry - Psychology: stock
# permutation_faculty <- data %>%
#   filter(Condition == 'stock') %>%
#   permutaion_test(data = ., group_var = 'Faculty')
# observed_difference <- data %>%
#   filter(Condition == 'stock') %>%
#   group_by(Faculty) %>%
#   summarise(mean = mean(cmx),
#               sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_faculty)
# 
# ## Chemistry - Psychology: zero
# permutation_faculty <- data %>%
#   filter(Condition == 'zero') %>%
#   permutaion_test(data = ., group_var = 'Faculty')
# observed_difference <- data %>%
#   filter(Condition == 'zero') %>%
#   group_by(Faculty) %>%
#   summarise(mean = mean(cmx),
#               sd = sd(cmx))
# p_value(observed_difference = observed_difference, distribution = permutation_faculty)

```

Before conducting a more detailed analysis, we tested the hypothesis whether the mathematical experience and the task definition condition affect the overall value of the series complexity. For testing these hypotheses we followed following one-sided permutation test of mean difference procedure. First, from the results, we resampled without replacement relevant groups 100,000 times. Second, for each resampling, we computed the difference between group means. Third, we calculated p-value as the proportion of the number of resampled difference greater than the observed difference to all resampled differences (the reproducible R script is in Appendix A). To test the hypothesis that students with more mathematical experience will produce series more complex than others we compared the difference between mean algorithmic complexity of series produced by chemistry students and psychology students. The difference between mean algorithmic complexity in group of psychology students ($M = .757,\ SD = .223$) and chemistry students ($M = .771, SD = .218$) was insignificant, $p = .33$. 

Although this result suggests that the mathematical experience does not affect the overall algorithmic complexity of produced series we would argue that this conclusion needs further examination. In this study, we interfered with mathematical experience based on the field of studies. Therefore, we did not control for individual differences. 

However, there were significant differences of mean algorithmic complexity between the task definiton coditions. The  mean algorithmic complexity in the Coin Tossing Condition ($M = .797,\ SD = .193$) was greater than in the No Instruction Condition ($M = .698,\ SD = .267$), $p = .01$. Simirarly, the mean algorithmic complexity in the Stock Market Condition ($M = .793, SD = .184$) was greater than in the No Instruction Condition ($M = .698,\ SD = .267$), $p = .01$. Only the difference in means between the Coin Tossing Condition and the Stock Martket Condition was insignificant, $p = .46$.

It indicates that the task definition conditions affect the overall algorithmic complexity of produced series. In the conditions (the Coin Tossing and the Stock Market conditions), in which task was defined in less abstract manner participants produced more complex series than in the No Instruction condition.

In a more detailed analysis, we used the rolling algorithmic complexity. We used the linear mixed-effects model to test following hypotheses: 1) the algorithmic complexity decreases over time, 2) the task definition moderates the effect of time on algorithmic complexity of the series, and, 3) the mathematical experience moderates the effect of time on algorithmic complexity of the series. We present herein analysis for a sliding window of the length 8 only. That is because this model fitted the data the best. The specification of the rest of the models is in Appendix A together with a replicable R script. The dependent variable (the algorithmic complexity) in the models was logged so back-transformed model predictions were bounded to be non-negative since there is no notion of negative randomness / algorithmic complexity. In all models as fixed effects we entered the timestep, the task abstraction condition (with No Instruction Condition as a reference level in dummy coding), the mathematical experience condition (with Chemistry as a reference level in dummy coding) and interaction terms between the timestep and the task abstraction condition, and between the timestep and the mathematical experience condition. Goodness-of-fit of the models was assessed with marginal $R^2$ (variance retained by fixed effects only) and conditional $R^2$ (variance retained by the model as such).

In the model with the sliding window of length 8 as random effects, we had an intercept for subjects. The fitted model indicated several significant effects. There was a significant negative effect of the timestep on the algorithmic complexity, $t(49376)=4.798,\ p<.001$. With each timestep, the algorithmic complexity decreased $.009\%\ \pm.002$. This result supported the first hypothesis regarding the observed decline in the algorithmic complexity over time. However, hypothesis two and three were not supported. Neither the task definition nor the level of mathematical experience moderated the effect of timestep on the algorithmic complexity (the detailed results are presented in Table 1.). However, similarly to the overall algorithmic complexity, there were significant differences between task definition conditions.  The algorithmic complexity in the Coin Tossing Condition was $2.814\%\ \pm.954$ higher than in the No Instruction Condition, $t(169)=2.948,\ p=.004$. Similarly, in the Stock Market condition, the algorithmic complexity was higher $2.82\%\ \pm.962$ than in the No Instruction Condition, $t=2.931,\ p=.004$. 

The results suggest that although there is a significant difference between task definition conditions in average algorithmic complexity it does not affect the effect of the timestep on the algorithmic complexity. The decline is constant across all conditions.

```{r table1}
Predictors_names <- rownames(coef(summary(model8.5)))
coef(summary(model8.5)) %>% 
  as.tibble() %>% 
  mutate(Predictors = Predictors_names) %>%
  select(Predictors,
         "Estimates" = 1,
         "Std. Error" = 2,
         "df*"=DF,
         "t-value",
         "p-value") %>%
  kable(caption = "Table 1. Model specification") %>%
  footnote(general = 'Marginal R2 = 3.93%, Conditional R2=37.48% \nStd. Deviation of the random individual effects s=.048, p<.001 \n\\*Deegres of Freedom were adjusted with the Satterthwaiter Method \nThe model accounted for first-order autoregressive errors corelation structure')
```

### Study 2.2.

In the second study, participants were recruited through the Polish Nationwide Opinion Poll Ariadna. It is a Polish Online Opinion Poll often used to conduct political surveys or scientific research. Depending on the declared length of the study users are gratified with points which they can exchange for prizes. During the research, participants were asked to produce 10 twelve elements binary series and to complete Polish versions of the Need for Cognition and the Need for Clouser Scales. 

```{r load_and_prepare_data2}
data2 <- read_sav("dane/Zbiór_Biesaga_los_ostateczny_v1.sav") %>%
  mutate(id = 1:n()) %>%
  select(-Id) %>%
  filter(survey_finish_time >= 656 & survey_finish_time < 1708)

data2_long <- data2 %>%
  gather(key = "Index", value = "Bit", matches("war[[:digit:]]")) %>%
  filter(!is.na(Bit)) %>% 
  filter(Bit != 99) %>% 
  mutate(klucz = if_else(grepl(x = Index, pattern = "time"), 'time', 'seq')) %>%
  select(id, Bit, klucz) %>%
  group_by(id, klucz) %>%
  mutate(idx = 1:n()) %>%
  spread(klucz, Bit) %>%
  filter(!is.na(seq)) %>%
  select(id, seq) %>%
  group_by(id) %>%
  summarise(seq = list(seq)) %>%
  filter(lengths(seq)>99)
```

#### 2.2.1. Procedure and Design

The study followed an experimental design, including one two-level between-subjects variable. First, participants were at random assigned to either the homogeneous instruction condition or the heterogeneous instruction condition. In both conditions, similarly to study 1, participants saw a red square every two seconds in ten 12 displays series. In the homogeneous condition for each series, they were asked to imagine tossing a fair coin and report the result whenever they saw a red square. In the heterogeneous instruction condition, their task altered every second series. In the odd series, they were asked to imagine tossing a fair coin and report the result whenever they saw a red square. In the even series, participants were asked to imagine a stock market chart and to assume that price fluctuation is generated by a random process. They were instructed to try to predict whether the prices will go up or down and to report the outcome every time they saw a red square. After completing the procedure of generating random series participants in both conditions were asked to fill in Polish versions of the Need for Cognition and the Need for Closure Scales.

#### 2.1.2. Participants

The participants were recruited through the Polish Nationwide Opinion Poll Ariadna. It is a Polish Online Opinion Poll often used to conduct political surveys or scientific research. Depending on the declared length of the study users are gratified with points which they can exchange for prizes. A total number of $266$ subjects agreed to take part in the study. However, due to the unrealistic (short or long) time of completion and unfinished surveys we excluded 80 participants. Therefore, finally we had a sample of 186 participants ($134$ females), aged from $18$ to $77$ ($M = 39.32,\ SD = 13.08$). They were at random assigned to one of the experimental conditions. The procedure was approved by the ethics committee of the Robert Zajonc Institute for Social Studies at the University of Warsaw. All participants gave informed consent before taking part in the study. 

#### 2.1.3. Data manipulation

In online research, it is crucial to measure survey time and exclude participants who completed the task in unrealistic (short or long) time. In our case, we removed 15\% of the shortest answers and 15\% of the longest. Although the participants were instructed to only press relevant keys when they saw a red square some people pressed it less frequent than 120 times. Therefore, the length of the series varies between subjects from 100 to 120 elements ($Median=114$). 

We used „pybdm” library in Python to compute algorithmic complexity of each series. It is an implementation of Block Decomposition Method which allows extending the power of Coding Theorem Method on longer strings. All other analyses were performed using R (R Core Team, 2019). We used packages "dplyr” (version 0.8.1), "magrittr” (version 1.5),  "lavaan" (version 0.6), and "ggplot2" (version 3.2.0) for data manipulation, processing, visualisation, and structural equation modeling. 

For each participant, we computed the overall value of the series complexity and the rolling algorithmic complexity. The latter was based on the computation of algorithmic complexity for a sliding window of length from 5 to 9. That is because the length of the working memory capacity is $7\pm2$ bits of information. We calculated algorithmic complexity for all the lengths separately and performed the analysis for all the lengths.

```{python compute_algorithmic_complexity2}
import numpy as np
import pandas as pd
from bdm import BDMRecursive as BDM

def window_bdm(seq, bdm, k=7):
    return np.array([ bdm.bdm(seq[i:(i+k)]) for i in range(len(seq) - k) ])
    
data = r.data2_long
data.id = data.id.astype(int)
data.seq = data.seq.apply(lambda x: np.array(x, dtype=int))

bdm = BDM(ndim=1, min_length=7)
seq7 = pd.DataFrame({'id': r.data2_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm))})

bdm = BDM(ndim=1, min_length=5)
seq5 = pd.DataFrame({'id': r.data2_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 5))})

bdm = BDM(ndim=1, min_length=9)
seq9 = pd.DataFrame({'id': r.data2_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 9))})
                     
bdm = BDM(ndim=1, min_length=11)
seq11 = pd.DataFrame({'id': r.data2_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 11))})

bdm = BDM(ndim=1, min_length=13)
seq13 = pd.DataFrame({'id': r.data2_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 13))})
                     
bdm = BDM(ndim=1, min_length=15)
seq15 = pd.DataFrame({'id': r.data2_long.id.astype(int),
                     'cmx': data.seq.apply(bdm.nbdm),
                     'cmx_w': data.seq.apply(lambda x: window_bdm(x, bdm, k = 15))})
                     


#seq5 = seq5.loc[seq5.cmx >= seq5.cmx.quantile(.05), :]
#seq7 = seq7.loc[seq7.cmx >= seq7.cmx.quantile(.05), :]
#seq9 = seq9.loc[seq9.cmx >= seq9.cmx.quantile(.05), :]
```


```{r}

seq7 <- py$seq7


data2 <- data2 %>%
  rename_at(vars(matches("^v1_r\\d+")),
            ~str_extract(string = .x, pattern = '\\d+$') %>%
              str_c("pzp", .)) %>%
  rename_at(vars(matches("^v2_r\\d+")),
            ~str_extract(string = .x, pattern = '\\d+$') %>%
              str_c('pp', .)) %>%
  mutate_at(vars(matches("pp\\d+")), ~as.numeric(.)) %>%
  mutate_at(vars(matches("pzp\\d+")), ~as.numeric(.)) %>%
  mutate_at(vars(matches("pp[2, 3, 8, 10, 13, 15, 17, 19, 22, 26, 28, 33, 34, 35]")), ~{6-.}) %>%
  mutate_at(vars(matches("pzp[2, 5, 10, 14, 15, 16, 17, 18, 20, 24, 30, 31]")), ~{7-.}) %>%
  mutate(year = as.numeric(year)) %>%
  select(-age) %>%
  left_join(seq7 %>% select(id,cmx)) %>%
  filter(!is.na(cmx))
  
seq7 <- seq7 %>%
  unnest() %>%
  group_by(id) %>%
  mutate(idx = 1:n(),
         cmx_r = rollmean(cmx_w, k = 7, align = "center", na.pad = TRUE)) %>%
  ungroup() %>%
  left_join(data2 %>% select(-cmx)) 

```
#### 2.2.4 Results
First, similarly to the results of study 1 we focused on the overall value of complexity for each participant. We tested hypothesis regarding the difference between the experimental conditions and the relationships between algorithmic complexity, need for cognition and need for closure.


```{r}
seq7 <- seq7 %>%
  rowwise() %>%
  mutate(preferowanie_porzadku = sum(pzp1, pzp6, pzp17, pzp19, pzp26, pzp27, pzp28),
         preferowanie_przewidywalnosci = sum(pzp5, pzp7, pzp9, pzp15, pzp16, pzp21, pzp22, pzp32),
         nietolerowanie_wieloznacznosci = sum(pzp3, pzp8, pzp12, pzp24, pzp25, pzp29),
         zamknietosc_umyslowa = sum(pzp2, pzp4, pzp20, pzp23, pzp30, pzp31),
         zdecydowniae = sum(pzp10, pzp11, pzp13, pzp14, pzp18),
         potrzeba_poznania = pp1 + pp2 + pp3 + pp4 + pp5 + pp6 + pp7 + pp8 + pp9 + pp10 +
                             pp11 + pp12 + pp13 + pp14 + pp15 + pp16 + pp17 + pp18 + pp19 + pp20 +
                             pp21 + pp22 + pp23 + pp24 + pp25 + pp26 + pp27 + pp28 + pp29 + pp30 +
                             pp31 + pp32 + pp33 + pp34 + pp35 + pp36)



seq7 %>%
```

```{r confirmatory}
model_nfclosure <- '
          zamknietowsc_umyslowa =~ pzp2 + pzp4 + pzp20 + pzp23 + pzp30 + pzp31
          nietolerowanie_wieloznacznosci =~ pzp3 + pzp8 + pzp12 + pzp25 + pzp29
          zdecydowanie =~ pzp10  + pzp14 + pzp18 + pzp11 + pzp13
          preferowanie_porzadku =~ pzp1 + pzp6 +  pzp19 + pzp26 + pzp27 + pzp28 + pzp17
          preferowanie_przewidywalnosci =~ pzp5 + pzp7 + pzp9 + pzp15 + pzp16 + pzp21 +  pzp22 + pzp32'

fit_nfclosure <- cfa(model_nfclosure, data2)

summary(fit_nfclosure, fit.measures=TRUE, standardized = TRUE)

parTable(fit_nfclosure)
standardizedSolution(fit_nfclosure, type="std.all")
inspect(fit_nfclosure, what = 'cor.all')
lavCor(fit_nfclosure)
resid(fit_nfclosure, "cor")
```


```{r lavaan_first}

model_cmx <- 'cmx ~ potrzeba_poznania + 
                #zamknietosc_umyslowa +
                nietolerowanie_wieloznacznosci +
                #zdecydowanie +
                preferowanie_porzadku +
                preferowanie_przewidywalnosci
          potrzeba_poznania =~ pp1 + pp2 + pp3 + pp4 + pp5 +pp6 + pp7 + pp8 + pp9 + pp10 +
                               pp11 + pp12 + pp13 + pp14 + pp15 + pp16 + pp17 + pp18 + pp19 + pp20 +
                               pp21 + pp22 + pp23 + pp24 + pp25 + pp26 + pp27 + pp28 + pp29 + pp30 +
                               pp31 + pp32 + pp33 + pp34 + pp35 + pp36
          #zamknietosc_umyslowa =~ pzp2 + pzp4 + pzp20 + pzp23 + pzp30 + pzp31
          nietolerowanie_wieloznacznosci =~ pzp3 + pzp8 + pzp12 + pzp25 + pzp29
          #zdecydowanie =~ pzp10 + pzp11 + pzp13 + pzp14 + pzp18
          preferowanie_porzadku =~ pzp1 + pzp6 + pzp17 + pzp19 + pzp26 + pzp27 + pzp28
          preferowanie_przewidywalnosci =~ pzp5 + pzp7 + pzp9 + pzp15 + pzp16 + pzp21 + pzp22 + pzp32
          pp19 ~~ pp28
          pp3 ~~ pp22
          pp2 ~~ pp22
          pp15 ~~ pp34
          pp10 ~~ pp35
          pp15 ~~ pp17
          pp13 ~~ pp22
          pp23 ~~ pp31
          pp2 ~~ pp13
          pp8 ~~ pp26
          pp26 ~~ pp33
          pp10 ~~ pp13
          pp24 ~~ pp31
          pp2 ~~ pp10
          pp24 ~~ pp32
          pp16 ~~ pp27
          pp7 ~~ pp16
          pp7 ~~ pp34
          pp9 ~~ pp20
          pzp15 ~~ pzp16
          pzp6 ~~ pzp27
          pzp5 ~~ pzp15
          pp8 ~~ pp33
          pp17 ~~ pp34
          pzp5 ~~ pzp21'


fit_cmx <- sem(model_cmx, data2)

summary(fit_cmx, standardized=TRUE, fit.measures = TRUE)

semPaths(fit_cmx)
modificationindices(fit_cmx, sort. = TRUE, minimum.value = 10)
```
 2, 3, 8, 10, 13, 15, 17, 19, 22, 26, 28, 33, 34, 35
 
 preferowanie_porzadku = sum(pzp1, pzp6, pzp17, pzp19, pzp26, pzp27, pzp28),
         preferowanie_przewidywalnosci = sum(pzp5, pzp7, pzp9, pzp15, pzp16, pzp21, pzp22, pzp32),
         nietolerowanie_wieloznacznosci = sum(pzp3, pzp8, pzp12, pzp24, pzp25, pzp29),
         zamknietosc_umyslowa = sum(pzp2, pzp4, pzp20, pzp23, pzp30, pzp31),
         zdecydowniae = sum(pzp10, pzp11, pzp13, pzp14, pzp18)) %>%